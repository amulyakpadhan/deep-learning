{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L6XOvPoQ5k93",
    "outputId": "3ab12d47-32f1-4c63-b167-c69c80e10d8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LwG1X5zNxEL8",
    "outputId": "ff331c97-20d4-4c22-cf7c-c9e40bf7dbcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 01m 19s]\n",
      "val_accuracy: 0.9915833473205566\n",
      "\n",
      "Best val_accuracy So Far: 0.9929166436195374\n",
      "Total elapsed time: 00h 14m 36s\n",
      "\n",
      "Best Hyperparameters:\n",
      "- Filters in Conv2D layers: 80 and 128\n",
      "- Kernel sizes: 5 and 5\n",
      "- Dense layer units: 96\n",
      "- Dropout rate: 0.4\n",
      "- Optimizer: adam\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8791 - loss: 0.3707 - val_accuracy: 0.9840 - val_loss: 0.0555\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.0613 - val_accuracy: 0.9898 - val_loss: 0.0371\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9875 - loss: 0.0395 - val_accuracy: 0.9897 - val_loss: 0.0405\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0337 - val_accuracy: 0.9901 - val_loss: 0.0325\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0246 - val_accuracy: 0.9918 - val_loss: 0.0311\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.0238 - val_accuracy: 0.9912 - val_loss: 0.0382\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0182 - val_accuracy: 0.9905 - val_loss: 0.0346\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0168 - val_accuracy: 0.9910 - val_loss: 0.0382\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0141 - val_accuracy: 0.9905 - val_loss: 0.0391\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0119 - val_accuracy: 0.9906 - val_loss: 0.0444\n",
      "Test Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras_tuner import Hyperband\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Normalize the data to [0, 1] range and reshape for CNN input\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Define the model-building function for hyperparameter tuning\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Hyperparameter for the number of filters in Conv2D layers\n",
    "    model.add(Conv2D(\n",
    "        filters=hp.Int('filters_1', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('kernel_size', values=[3, 5]),\n",
    "        activation='relu',\n",
    "        input_shape=(28, 28, 1)\n",
    "    ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(\n",
    "        filters=hp.Int('filters_2', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('kernel_size_2', values=[3, 5]),\n",
    "        activation='relu'\n",
    "    ))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # Hyperparameter for the number of units in Dense layers\n",
    "    model.add(Dense(units=hp.Int('units', min_value=64, max_value=256, step=32), activation='relu'))\n",
    "    model.add(Dropout(hp.Float('dropout', min_value=0.2, max_value=0.5, step=0.1)))\n",
    "    model.add(Dense(units=10, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=hp.Choice('optimizer', values=['adam', 'sgd']),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# Initialize the Keras Tuner\n",
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='hyperparameter_tuning',\n",
    "    project_name='mnist_cnn_tuning'\n",
    ")\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train, y_train, epochs=10, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "Best Hyperparameters:\n",
    "- Filters in Conv2D layers: {best_hps.get('filters_1')} and {best_hps.get('filters_2')}\n",
    "- Kernel sizes: {best_hps.get('kernel_size')} and {best_hps.get('kernel_size_2')}\n",
    "- Dense layer units: {best_hps.get('units')}\n",
    "- Dropout rate: {best_hps.get('dropout')}\n",
    "- Optimizer: {best_hps.get('optimizer')}\n",
    "\"\"\")\n",
    "\n",
    "# Train the best model\n",
    "best_model = tuner.hypermodel.build(best_hps)\n",
    "best_model.fit(X_train, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = best_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Define the grid of hyperparameters\n",
    "filter_options = [32, 64]\n",
    "kernel_size_options = [3, 5]\n",
    "units_options = [64, 128]\n",
    "dropout_options = [0.2, 0.3]\n",
    "optimizer_options = ['adam', 'sgd']\n",
    "\n",
    "# Iterate through all combinations of hyperparameters\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "for filters_1 in filter_options:\n",
    "    for filters_2 in filter_options:\n",
    "        for kernel_size in kernel_size_options:\n",
    "            for units in units_options:\n",
    "                for dropout in dropout_options:\n",
    "                    for optimizer in optimizer_options:\n",
    "                        print(f\"Training with filters: {filters_1}, {filters_2}, kernel_size: {kernel_size}, units: {units}, dropout: {dropout}, optimizer: {optimizer}\")\n",
    "                        \n",
    "                        # Define the CNN model\n",
    "                        model = Sequential([\n",
    "                            Conv2D(filters=filters_1, kernel_size=(kernel_size, kernel_size), activation='relu', input_shape=(28, 28, 1)),\n",
    "                            MaxPooling2D(pool_size=(2, 2)),\n",
    "                            Conv2D(filters=filters_2, kernel_size=(kernel_size, kernel_size), activation='relu'),\n",
    "                            MaxPooling2D(pool_size=(2, 2)),\n",
    "                            Flatten(),\n",
    "                            Dense(units=units, activation='relu'),\n",
    "                            Dropout(dropout),\n",
    "                            Dense(units=10, activation='softmax')\n",
    "                        ])\n",
    "                        \n",
    "                        # Compile the model\n",
    "                        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                        \n",
    "                        # Train the model\n",
    "                        model.fit(X_train, y_train, epochs=3, batch_size=32, validation_split=0.2, verbose=0)\n",
    "                        \n",
    "                        # Evaluate the model\n",
    "                        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "                        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "                        \n",
    "                        # Keep track of the best model\n",
    "                        if accuracy > best_accuracy:\n",
    "                            best_accuracy = accuracy\n",
    "                            best_params = {\n",
    "                                'filters_1': filters_1,\n",
    "                                'filters_2': filters_2,\n",
    "                                'kernel_size': kernel_size,\n",
    "                                'units': units,\n",
    "                                'dropout': dropout,\n",
    "                                'optimizer': optimizer\n",
    "                            }\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Test Accuracy: {best_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
