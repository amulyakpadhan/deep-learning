{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Total Error = 12, Total Weight Change = 2.5455844122715714\n",
      "Epoch 2: Total Error = 12, Total Weight Change = 2.5455844122715714\n",
      "Epoch 3: Total Error = 0, Total Weight Change = 0\n",
      "Training stopped after 3 epochs. No significant weight changes.\n",
      "Input: [-1  1], Output: 1\n",
      "Input: [ 1 -1], Output: -1\n",
      "Input: [1 1], Output: 1\n",
      "Input: [-1 -1], Output: -1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation function (sign function for bipolar inputs)\n",
    "def activation(x):\n",
    "    return np.where(x >= 0, 1, -1)\n",
    "\n",
    "# Initialize weights and bias\n",
    "def initialize_weights(input_size, num_units):\n",
    "    weights = np.random.randn(num_units, input_size)  # Random weights for each Adaline unit\n",
    "    bias = np.random.randn(num_units)  # Random bias for each Adaline unit\n",
    "    return weights, bias\n",
    "\n",
    "# Forward pass for a single Adaline unit\n",
    "def adaline_forward(x, weights, bias):\n",
    "    return activation(np.dot(x, weights) + bias)\n",
    "\n",
    "# Forward pass for the Madaline network (multiple Adaline units)\n",
    "def madaline_forward(X, weights, bias):\n",
    "    outputs = np.array([adaline_forward(X, weights[i], bias[i]) for i in range(weights.shape[0])])\n",
    "    # Final Madaline output (majority vote or sum of outputs, then apply activation)\n",
    "    return activation(np.sum(outputs))\n",
    "\n",
    "# Update weights and bias\n",
    "def update_weights(X, error, weights, bias, learning_rate):\n",
    "    weight_change = 0  # Track total weight change\n",
    "    for i in range(weights.shape[0]):\n",
    "        old_weights = weights[i].copy()  # Save the old weights\n",
    "        weights[i] += learning_rate * error * X  # Adjust weights\n",
    "        bias[i] += learning_rate * error  # Adjust bias\n",
    "        # Calculate total weight change (L2 norm)\n",
    "        weight_change += np.linalg.norm(weights[i] - old_weights)\n",
    "    return weight_change\n",
    "\n",
    "# Train the Madaline network\n",
    "def train_madaline(X, y, num_units, learning_rate=0.01, tolerance=1e-3):\n",
    "    input_size = X.shape[1]\n",
    "    weights, bias = initialize_weights(input_size, num_units)\n",
    "\n",
    "    epoch = 0\n",
    "    while True:\n",
    "        total_error = 0\n",
    "        total_weight_change = 0\n",
    "        for i in range(len(X)):\n",
    "            output = madaline_forward(X[i], weights, bias)\n",
    "            error = y[i] - output\n",
    "            total_error += error ** 2\n",
    "\n",
    "            if error != 0:\n",
    "                weight_change = update_weights(X[i], error, weights, bias, learning_rate)\n",
    "                total_weight_change += weight_change\n",
    "\n",
    "        epoch += 1\n",
    "        print(f\"Epoch {epoch}: Total Error = {total_error}, Total Weight Change = {total_weight_change}\")\n",
    "\n",
    "        # Stop if total weight change is below tolerance\n",
    "        if total_weight_change < tolerance:\n",
    "            print(f\"Training stopped after {epoch} epochs. No significant weight changes.\")\n",
    "            break\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "# Testing the Madaline network\n",
    "def test_madaline(X, weights, bias):\n",
    "    for i in range(len(X)):\n",
    "        output = madaline_forward(X[i], weights, bias)\n",
    "        print(f\"Input: {X[i]}, Output: {output}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example input data (bipolar inputs) and corresponding labels\n",
    "    X = np.array([[-1, 1], [1, -1], [1, 1], [-1, -1]])  # Example input\n",
    "    y = np.array([1, -1, 1, -1])  # Corresponding labels\n",
    "\n",
    "    # Train the Madaline network with 3 Adaline units\n",
    "    num_units = 3\n",
    "    learning_rate = 0.1\n",
    "    tolerance = 1e-5  # Small tolerance to stop training when weight updates are minimal\n",
    "    weights, bias = train_madaline(X, y, num_units, learning_rate, tolerance)\n",
    "\n",
    "    # Test the Madaline network\n",
    "    test_madaline(X, weights, bias)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
