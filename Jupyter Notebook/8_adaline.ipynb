{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Weights: [0.97647377 0.75199877]\n",
      "Initial Bias: [0.88862613]\n",
      "final weights:  [-0.00942256 -0.00437825]\n",
      "final bias:  [0.50423956]\n",
      "Input: [0 0], Predicted: [0.50423956], Actual: 0\n",
      "Input: [0 1], Predicted: [0.49986131], Actual: 1\n",
      "Input: [1 0], Predicted: [0.494817], Actual: 1\n",
      "Input: [1 1], Predicted: [0.49043875], Actual: 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "# Adaline Activation Function (Linear)\n",
    "def activation_function(x):\n",
    "    return x\n",
    "\n",
    "# Adaline training function\n",
    "def adaline_training(X, D, learning_rate=0.01, epochs=100):\n",
    "    num_samples, num_features = X.shape\n",
    "    weights = np.random.rand(num_features)\n",
    "    bias = np.random.rand(1)\n",
    "    print(\"Initial Weights:\", weights)\n",
    "    print(\"Initial Bias:\", bias)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_error = 0\n",
    "        for i in range(num_samples):\n",
    "            # Calculate the network output Y (weighted sum)\n",
    "            net_input = np.dot(X[i], weights) + bias\n",
    "            Y = activation_function(net_input)\n",
    "\n",
    "            # Calculate the error (D - Y)\n",
    "            error = D[i] - Y\n",
    "            total_error += error**2\n",
    "\n",
    "            # Update weights and bias using delta rule\n",
    "            weights += learning_rate * error * X[i]\n",
    "            bias += learning_rate * error\n",
    "\n",
    "        # Stop if the error is sufficiently small\n",
    "        if total_error < 1e-4:\n",
    "            print(f\"Training stopped after {epoch+1} epochs.\")\n",
    "            break\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "# Input dataset XOR\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "D = np.array([0, 1, 1, 0])\n",
    "\n",
    "# Set learning rate and epochs\n",
    "learning_rate = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "# Train the Adaline network\n",
    "weights, bias = adaline_training(X, D, learning_rate, epochs)\n",
    "print(\"final weights: \",weights)\n",
    "print(\"final bias: \",bias)\n",
    "# Testing the Adaline model on the dataset\n",
    "def predict(X, weights, bias):\n",
    "    net_input = np.dot(X, weights) + bias\n",
    "    return activation_function(net_input)\n",
    "\n",
    "# Testing\n",
    "for i in range(len(X)):\n",
    "    print(f\"Input: {X[i]}, Predicted: {predict(X[i], weights, bias)}, Actual: {D[i]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
